{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e92a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JulianaBaumgartnerov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"kt_dir\", ignore_errors=True)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76501700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of city - used only in output file name\n",
    "city = \"Kolkata\"\n",
    "# load result from 2.0 training_to_parquet\n",
    "training_data_file = r\"\"  # \"enhanced_formal.parquet\"\n",
    "\n",
    "# load result from 1.0 real data\n",
    "real_data_file = r\"\" # \"20250519_04_countBuildingsInSquare_mumbaiAll_Filtered_50x50.parquet\"\n",
    "\n",
    "# define name/path where classification report should be saved - no extension -> will be added in the code\n",
    "classification_rpt = r\"\"\n",
    "\n",
    "# define name/path where confusion matrix should be saved.\n",
    "confusion_mtrx = r\"\"\n",
    "\n",
    "# output geojson file\n",
    "output_file = r\"\"  # f\"NN_chennai_colored_50x50_without_trees_v2.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd035017",
   "metadata": {},
   "source": [
    "#### Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e214bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load result from 2.0 training_to_parquet\n",
    "df = pd.read_parquet(training_data_file)\n",
    "# df.to_csv(\"data/origData/results/split_universe_with_median_height.csv\") - better use parquet\n",
    "\n",
    "#drop unused columns, leave only the ones needed for computation\n",
    "df_adjusted = df.drop(\n",
    "    columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"id\", \"geometry\", \"polygon\", \"tile\", \"num_pixels_ge_3m\"]\n",
    ")\n",
    "\n",
    "df_cleaned = df_adjusted.fillna(0)\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "df_cleaned[\"avg_area_norm\"] = df_cleaned[\"avg_area\"] / 3000\n",
    "df_cleaned.loc[df_cleaned[\"avg_area\"] > 3000, \"avg_area_norm\"] = 1\n",
    "\n",
    "df_cleaned[\"max_area_norm\"] = df_cleaned[\"max_area\"] / 3000\n",
    "df_cleaned.loc[df_cleaned[\"max_area\"] > 3000, \"max_area_norm\"] = 1\n",
    "\n",
    "df_cleaned[\"avg_height_norm\"] = df_cleaned[\"avg_height\"] / 100\n",
    "df_cleaned.loc[df_cleaned[\"avg_height\"] > 3000, \"avg_height_norm\"] = 1\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=[\"avg_area\", \"max_area\", \"avg_height\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from kt_dir\\text_classifier_tuning\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulianaBaumgartnerov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\JulianaBaumgartnerov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.3700  \n",
      "Test Accuracy: 0.79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,713</span> (6.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,713\u001b[0m (6.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,713</span> (6.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,713\u001b[0m (6.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate features (X) and label (y)\n",
    "X = df_cleaned.drop(\"class\", axis=1)\n",
    "y = df_cleaned[\"class\"]\n",
    "\n",
    "y = y.map({\"formal\": 0, \"informal\": 1})\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(24, activation=\"relu\", name=\"dense_0\"))\n",
    "\n",
    "    # Second hidden layers\n",
    "    model.add(Dense(88, activation=\"relu\", name=\"dense_1\"))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Set up early stopping\n",
    "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Try 10 different combinations\n",
    "    executions_per_trial=1,\n",
    "    directory='kt_dir',\n",
    "    project_name='text_classifier_tuning'\n",
    ")\n",
    "\n",
    "# Run search\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[earlystopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82080b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary labels\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=[\"formal\", \"informal\"],\n",
    "    yticklabels=[\"formal\", \"informal\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "\n",
    "# Save IMAGE to file\n",
    "plt.tight_layout()\n",
    "plt.savefig(confusion_mtrx, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c02b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred, target_names=[\"formal\", \"informal\"])\n",
    "print(report)\n",
    "\n",
    "with open(f\"{classification_rpt}_{city}.txt\", \"w\") as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c385e539",
   "metadata": {},
   "source": [
    "### REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "real_df = pd.read_parquet(real_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same with training - drop unnecesary columns\n",
    "real_df_adjusted = real_df.drop(\n",
    "    columns=[\"Unnamed: 0\", \"class\", \"id\", \"geometry\", \"polygon\"]\n",
    ")\n",
    "\n",
    "real_df_cleaned = real_df_adjusted.fillna(0)\n",
    "\n",
    "# print(real_df_cleaned.columns)\n",
    "# print(real_df_cleaned.head(5))\n",
    "\n",
    "# Normalize data\n",
    "real_df_cleaned[\"avg_area_norm\"] = real_df_cleaned[\"avg_area\"] / 3000\n",
    "real_df_cleaned.loc[real_df_cleaned[\"avg_area\"] > 3000, \"avg_area_norm\"] = 1\n",
    "\n",
    "real_df_cleaned[\"max_area_norm\"] = real_df_cleaned[\"max_area\"] / 3000\n",
    "real_df_cleaned.loc[real_df_cleaned[\"max_area\"] > 3000, \"max_area_norm\"] = 1\n",
    "\n",
    "real_df_cleaned[\"avg_height_norm\"] = real_df_cleaned[\"avg_height\"] / 100\n",
    "real_df_cleaned.loc[real_df_cleaned[\"avg_height\"] > 3000, \"avg_height_norm\"] = 1\n",
    "\n",
    "real_df_cleaned_adj = real_df_cleaned.drop(columns=[\"avg_area\", \"max_area\", \"avg_height\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31fb60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align columns with training data\n",
    "new_df = real_df_cleaned_adj.reindex(\n",
    "    columns=X.columns, fill_value=0\n",
    ")  # Ensure same structure\n",
    "\n",
    "# Scale using the SAME scaler (don’t fit again)\n",
    "new_scaled = scaler.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5767c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Predict probabilities\n",
    "pred_probs = model.predict(new_scaled)\n",
    "\n",
    "# Step 2: Convert to percentages (e.g., 0.82 → 82.0)\n",
    "percentages = (pred_probs * 100).round(2).flatten()  # Round to 2 decimal places\n",
    "\n",
    "# Step 3: Predict binary class from probabilities\n",
    "pred_classes = (pred_probs > 0.5).astype(int)  # Binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97607b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = [\"formal\" if label == 0 else \"informal\" for label in pred_classes]\n",
    "real_df[\"prediction\"] = predicted_classes\n",
    "real_df[\"confidence (%)\"] = percentages\n",
    "\n",
    "real_data_adjusted_df = real_df.drop(columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aff1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_filtered_df = real_data_adjusted_df[\n",
    "    real_data_adjusted_df[\"prediction\"] == \"informal\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "570c00d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JulianaBaumgartnerov\\AppData\\Local\\Temp\\ipykernel_33932\\402012916.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  real_data_filtered_df[\"polygon\"] = real_data_filtered_df[\"polygon\"].apply(wkt.loads)\n"
     ]
    }
   ],
   "source": [
    "# Convert WKT to shapely geometries\n",
    "from shapely import wkt\n",
    "\n",
    "real_data_filtered_df[\"polygon\"] = real_data_filtered_df[\"polygon\"].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1c93487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GeoJSON features\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "color_map = {\n",
    "    \"high\": \"#00cd00\", # green\n",
    "    \"mid\": \"#ff4d4d\", # red\n",
    "    # \"low\": \"#1591EA\", # blue\n",
    "}     \n",
    "\n",
    "features = []\n",
    "for _, row in real_data_filtered_df.iterrows():\n",
    "\n",
    "    confidence = row[\"confidence (%)\"]\n",
    "    color = (\n",
    "        color_map[\"high\"] if confidence > 60\n",
    "        else color_map[\"mid\"]\n",
    "    )\n",
    "\n",
    "    \n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"confidence\": round(row[\"confidence (%)\"], 2),\n",
    "            \"class\": row[\"prediction\"],\n",
    "            \"fill\": color,\n",
    "            \"stroke\": color\n",
    "        },\n",
    "        \"geometry\": mapping(row[\"polygon\"]),\n",
    "    }\n",
    "    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc6be35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in a FeatureCollection\n",
    "geojson_dict = {\"type\": \"FeatureCollection\", \"features\": features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to final file\n",
    "import json\n",
    "\n",
    "with open(output_file,\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(geojson_dict, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
